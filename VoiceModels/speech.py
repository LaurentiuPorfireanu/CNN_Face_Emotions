import torch
import sounddevice as sd
import numpy as np
from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, AutoTokenizer, AutoModelForSequenceClassification, pipeline

# Parametri generali
SAMPLE_RATE = 16000
CHANNELS = 1
BLOCK_DURATION = 2  # secunde pe batch

# ÃncarcÄƒ modelul romÃ¢nesc de speech-to-text
processor = Wav2Vec2Processor.from_pretrained("anton-l/wav2vec2-large-xlsr-53-romanian")
model_speech = Wav2Vec2ForCTC.from_pretrained("anton-l/wav2vec2-large-xlsr-53-romanian")

# ÃncarcÄƒ modelul public de analizÄƒ de sentiment (emoÈ›ie)
tokenizer_sentiment = AutoTokenizer.from_pretrained("cardiffnlp/twitter-roberta-base-sentiment")
model_sentiment = AutoModelForSequenceClassification.from_pretrained("cardiffnlp/twitter-roberta-base-sentiment")

sentiment_pipeline = pipeline(
    "sentiment-analysis",
    model=model_sentiment,
    tokenizer=tokenizer_sentiment
)

# Flag pentru oprire
stop_recording = False

def recognize_stream_with_emotion():
    """RecunoaÈ™te voce live + analizeazÄƒ emoÈ›ia"""
    global stop_recording
    print("ğŸ¤ RecunoaÈ™tere live pornitÄƒ! ApasÄƒ Ctrl+C pentru oprire...\n")

    def callback(indata, frames, time, status):
        if status:
            print(status)
        audio = np.squeeze(indata)

        # Speech-to-text
        inputs = processor(audio, return_tensors="pt", sampling_rate=SAMPLE_RATE, padding=True)
        with torch.no_grad():
            logits = model_speech(**inputs).logits
        predicted_ids = torch.argmax(logits, dim=-1)
        transcription = processor.batch_decode(predicted_ids)[0].strip()

        if transcription:
            # Analiza de emoÈ›ie
            emotion = sentiment_pipeline(transcription)[0]
            label = emotion['label']

            # InterpretÄƒm label-ul
            if label == 'LABEL_0':
                emotion_text = "ğŸ˜ EmoÈ›ie: NegativÄƒ"
            elif label == 'LABEL_1':
                emotion_text = "ğŸ˜ EmoÈ›ie: NeutrÄƒ"
            elif label == 'LABEL_2':
                emotion_text = "ğŸ˜Š EmoÈ›ie: PozitivÄƒ"
            else:
                emotion_text = f"ğŸ¤” EmoÈ›ie necunoscutÄƒ ({label})"

            # AfiÈ™Äƒm frumos emoÈ›ia È™i textul
            print(f"\n{emotion_text}\n\"{transcription}\"\n", flush=True)

    try:
        with sd.InputStream(samplerate=SAMPLE_RATE, channels=CHANNELS, dtype='float32',
                            blocksize=int(SAMPLE_RATE * BLOCK_DURATION),
                            callback=callback):
            while not stop_recording:
                sd.sleep(100)
    except KeyboardInterrupt:
        stop_recording = True
        print("\nğŸ›‘ RecunoaÈ™tere opritÄƒ.")

if __name__ == "__main__":
    recognize_stream_with_emotion()
